<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2020-05-20">
<meta name="description" content="A complete overview on Autoregressive Generative Models (MADE, PixelCNN families, WaveNet, Seft-Attention, PixelSNAIL) with implementation code">

<title>Machine learning Blog - Autoregressive Generative Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Machine learning Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mrtunguyen" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/jonathan_ttu" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Autoregressive Generative Models</h1>
                  <div>
        <div class="description">
          A complete overview on Autoregressive Generative Models (MADE, PixelCNN families, WaveNet, Seft-Attention, PixelSNAIL) with implementation code
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">generative</div>
                <div class="quarto-category">autoregressive</div>
                <div class="quarto-category">deeplearning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 20, 2020</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#autoregressive-generative-model" id="toc-autoregressive-generative-model" class="nav-link" data-scroll-target="#autoregressive-generative-model">Autoregressive Generative Model</a>
  <ul class="collapse">
  <li><a href="#masked-autoencoder-for-distribution-estimation-made" id="toc-masked-autoencoder-for-distribution-estimation-made" class="nav-link" data-scroll-target="#masked-autoencoder-for-distribution-estimation-made">Masked Autoencoder for Distribution Estimation (MADE)</a>
  <ul class="collapse">
  <li><a href="#autoencoder" id="toc-autoencoder" class="nav-link" data-scroll-target="#autoencoder">Autoencoder</a></li>
  <li><a href="#masked-autoencoders" id="toc-masked-autoencoders" class="nav-link" data-scroll-target="#masked-autoencoders">Masked Autoencoders</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  </ul></li>
  <li><a href="#pixelcnn" id="toc-pixelcnn" class="nav-link" data-scroll-target="#pixelcnn">PixelCNN</a>
  <ul class="collapse">
  <li><a href="#masked-spatial-convolution" id="toc-masked-spatial-convolution" class="nav-link" data-scroll-target="#masked-spatial-convolution">Masked spatial convolution</a></li>
  <li><a href="#blind-spot" id="toc-blind-spot" class="nav-link" data-scroll-target="#blind-spot">Blind spot</a></li>
  <li><a href="#gated-pixelcnn" id="toc-gated-pixelcnn" class="nav-link" data-scroll-target="#gated-pixelcnn">Gated PixelCNN</a></li>
  <li><a href="#conditional-pixelcnn" id="toc-conditional-pixelcnn" class="nav-link" data-scroll-target="#conditional-pixelcnn">Conditional PixelCNN</a></li>
  <li><a href="#implementation-1" id="toc-implementation-1" class="nav-link" data-scroll-target="#implementation-1">Implementation</a></li>
  </ul></li>
  <li><a href="#pixelcnn-1" id="toc-pixelcnn-1" class="nav-link" data-scroll-target="#pixelcnn-1">PixelCNN++</a></li>
  <li><a href="#wavenet" id="toc-wavenet" class="nav-link" data-scroll-target="#wavenet">WaveNet</a>
  <ul class="collapse">
  <li><a href="#dilated-convolution" id="toc-dilated-convolution" class="nav-link" data-scroll-target="#dilated-convolution">Dilated convolution</a></li>
  <li><a href="#softmax-distribution" id="toc-softmax-distribution" class="nav-link" data-scroll-target="#softmax-distribution">Softmax distribution</a></li>
  <li><a href="#fast-wavenet-generation" id="toc-fast-wavenet-generation" class="nav-link" data-scroll-target="#fast-wavenet-generation">Fast WaveNet Generation</a></li>
  <li><a href="#implementation-2" id="toc-implementation-2" class="nav-link" data-scroll-target="#implementation-2">Implementation</a></li>
  </ul></li>
  <li><a href="#self-attention-autoregressive-model" id="toc-self-attention-autoregressive-model" class="nav-link" data-scroll-target="#self-attention-autoregressive-model">Self-Attention Autoregressive Model</a>
  <ul class="collapse">
  <li><a href="#implementation-3" id="toc-implementation-3" class="nav-link" data-scroll-target="#implementation-3">Implementation</a></li>
  </ul></li>
  <li><a href="#pixelsnail" id="toc-pixelsnail" class="nav-link" data-scroll-target="#pixelsnail">PixelSNAIL</a>
  <ul class="collapse">
  <li><a href="#flexible-ordering" id="toc-flexible-ordering" class="nav-link" data-scroll-target="#flexible-ordering">Flexible ordering</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">Reference</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p><strong>Generative model</strong> is a subset of unsupervised learning which has been recieving a lot of attention for last few years. The idea is that given a training dataset, we will use models or algorithms to generate new samples with the same distribution.</p>
<pre><code>“What I cannot create, I do not understand.”
—Richard Feynman</code></pre>
<p>Suppose we have a dataset containing images of dogs. We may wish to build a model that can generate a new image of a dog that has never existed but still looks real because the model has learned the general rules that govern the appearance of a dog. This is the kind of problem that can be solved using <strong>generative modeling</strong>.</p>
<p>In mathematical terms, <strong>generative modeling</strong> estimates <span class="math inline">\(p(x)\)</span> —the probability of observing observation <span class="math inline">\(x\)</span>. In fact, our model tries to learn to construct an estimate <span class="math inline">\(p_{model}(x)\)</span> as similar as possible to the probability density function <span class="math inline">\(p_{data}(x)\)</span>.</p>
<p>In this blog, we will take a deep look at one of popular approaches to tackle this problem which is <strong>Autoregressive Generative Models</strong></p>
</section>
<section id="autoregressive-generative-model" class="level1">
<h1>Autoregressive Generative Model</h1>
<p>The idea behind this type of model is that if we consider all obversations as a sequence, the probability of observing one data point depends only on the previous ones but not the ones after it, we can compute <span class="math inline">\(p(x)\)</span> as a product of conditional distributions by applying <a href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">product rule</a>. In a nutshel, autoregressive models define the <strong>joint distribution</strong> using conditionals over each feature, given the values of the previous features.</p>
<p><span class="math display">\[\mathbf{p}(\mathbf{x}) = \prod_{i=1}^{N} \mathbf{x}_i = \prod_{i=1}^{N} \mathbf{p}\big(\mathbf{x}_i | \mathbf{x}_1, \mathbf{x}_2, ..., \mathbf{x}_{i-1}\big) \tag{1}\]</span></p>
<p>For example, we can use autoregressive generative models to predict the output at timestep t given its previous timesteps in text-to-speech problem. Or the probability of a pixel from an image to have a specific intensity value is conditioned by the values of all previous pixels; and the probability of an image (the joint distribution of all pixels) is the combination of the probability of all its pixels.</p>
<section id="masked-autoencoder-for-distribution-estimation-made" class="level2">
<h2 class="anchored" data-anchor-id="masked-autoencoder-for-distribution-estimation-made">Masked Autoencoder for Distribution Estimation (MADE)</h2>
<p>The idea of MADE is built on top of autoencoder architecture. So, we’ll have a quick look on vanila autoencoder.</p>
<section id="autoencoder" class="level3">
<h3 class="anchored" data-anchor-id="autoencoder">Autoencoder</h3>
<p>Our primary goal is take an input sample <span class="math inline">\(\mathbf{x}\)</span> and transform it to some latent dimension <span class="math inline">\(\mathbf{z}\)</span> (<strong>encoder</strong>), which hopefully is a good representation of the original data.</p>
<pre><code>what is a good representation?  
"A good representation is one where you can reconstruct the original input!". </code></pre>
<p>The process of transforming the latent dimension <span class="math inline">\(\mathbf{z}\)</span> back to a reconstructed version of the input <span class="math inline">\(\mathbf{\hat{x}}\)</span> is called the <strong>decoder</strong>. It’s an <strong>autoencoder</strong> because it’s using the same value <span class="math inline">\(\mathbf{x}\)</span> value on the input and output.</p>
<p>Mathematically, an <strong>encoder</strong> is mapping an input <span class="math inline">\(\mathbf{x}\)</span> to a feature vector <span class="math inline">\(\mathbf{h} = \mathbf{f}_{\theta}(\mathbf{x})\)</span> while a <strong>decoder</strong> tries to map from feature space back into input space producing a <strong>reconstruction</strong> <span class="math inline">\(\mathbf{\hat{x}}= \mathbf{g}_{\theta}(\mathbf{h}) = \mathbf{g}_{\theta}\big(\mathbf{f}_{\theta}(\mathbf{x})\big)\)</span>. The set of parameters <span class="math inline">\(\theta\)</span> of the encoder and decoder are learned simultaneously on the task of reconstructing as well as possible the original input, i.e.attempting to incur the lowest possible <strong>reconstruction error</strong> <span class="math inline">\(\mathcal{L}(\mathbf{x},\mathbf{\hat{x}})\)</span> - a measure of the discrepancy between <span class="math inline">\(\mathbf{x}\)</span> and its reconstruction <span class="math inline">\(\mathbf{\hat{x}}\)</span> - over training examples</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png" title="Figure 1: Vanilla autoencoder" class="img-fluid"></p>
<p>To train autoencoder, we use cross-entropy loss: <span class="math display">\[\begin{align*}
\mathcal{L_{\text{binary}}}({\bf \mathbf{x}}) &amp;= \sum_{i=1}^N -\mathbf{x}_i\log \hat{\mathbf{x}}_i - (1-\mathbf{x}_i)\log(1-\hat{\mathbf{x}_i}) \tag{2} \\
\end{align*}\]</span></p>
<p>To capture the structure of the data-generating distribution, it is therefore important that something in the training criterion or the parametrization prevents the auto-encoder from learning the identity function, which has zero reconstruction error everywhere. This is achieved through various means <strong>regularized autoencoders</strong> (refer to [3] to see more about it)</p>
</section>
<section id="masked-autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="masked-autoencoders">Masked Autoencoders</h3>
<p>Since autoencoder is to reconstruct the input from learning a latent representation of data in an unsupervised manner, it can’t provide a proper probability distribution. Therefore, it can usually be used in applications such as denoising images but can’t generate a total new sample.</p>
<p>The reason is that in autoencoder, each output <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> could depend on any of the components input <span class="math inline">\(\mathbf{x}_1,…,\mathbf{x}_n\)</span>. So in order to convert to our autoregressive models as defined above, we can modify the structure so that <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> only depend on previous components <span class="math inline">\(\mathbf{x}_1,…,\mathbf{x}_{i-1}\)</span> but not the future ones <span class="math inline">\(\mathbf{x}_{i+1},…,\mathbf{x}_n\)</span>.</p>
<p>The principle becomes as following: - Each output of the network <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> represents the probability distribution <span class="math inline">\(\mathbf{p}\big(\mathbf{x}_i | \mathbf{x}_{&lt;i}\big)\)</span></p>
<ul>
<li>Each output <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> can only have connections (recursively) to smaller indexed inputs <span class="math inline">\(\mathbf{x}_{&lt;i}\)</span> and not any of the other ones.</li>
</ul>
<p>To persuit this principle, the MADE authors came up with the idea of <strong>masked autoencoders</strong>. Since output <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> must depend only on the preceding inputs <span class="math inline">\(\mathbf{x}_{&lt;i}\)</span>, it means that there must be no computational path between output unit <span class="math inline">\(\mathbf{\hat{x}}_i\)</span> and any of the input units <span class="math inline">\(\mathbf{x}_i, ... \mathbf{x}_N\)</span>. To do so, we will <strong>zero-out the weights</strong> we don’t want by creating a binary mask matrix, whose entries that are set to 0 correspond to the connections we wish to remove.</p>
<p>Take a simple case when encoder and decoder are only one layer of feed-forward.</p>
<p><span class="math display">\[\begin{align*}
{\bf h}({\bf x}) &amp;= {\bf g}({\bf b} + {\bf Wx}) \\
{\hat{\bf x}} &amp;= \text{sigm}({\bf c} + {\bf V h(x)})  
\end{align*}\]</span></p>
<p>where - <span class="math inline">\(\odot\)</span> is an element wise product</p>
<ul>
<li><p><span class="math inline">\({\bf x}, \hat{\bf x}\)</span> is our vectors of input/output respectively</p></li>
<li><p><span class="math inline">\(\bf h(x)\)</span> is the hidden layer</p></li>
<li><p><span class="math inline">\(\bf g(⋅)\)</span> is the activation function of the hidden layer</p></li>
<li><p><span class="math inline">\(\text{sigm}\)</span> is the sigmoid activation function of the output layer</p></li>
<li><p><span class="math inline">\(\bf b\)</span>, <span class="math inline">\(\bf c\)</span> are the constant biases for the hidden/output layer respectively</p></li>
<li><p><span class="math inline">\(\bf W\)</span>, <span class="math inline">\(\bf V\)</span> are the weight matrices for the hidden/output layer respectively</p></li>
</ul>
<p>Denote <span class="math inline">\(\bf M^W\)</span>, <span class="math inline">\(\bf M^V\)</span> the masks for <span class="math inline">\(\bf W\)</span> and <span class="math inline">\(\bf V\)</span> respectively. The equations with masked autoencoders become:</p>
<p><span class="math display">\[\begin{align*}
{\bf h}({\bf x}) &amp;= {\bf g}({\bf b} + {\bf (W \odot M^W)x}) \\
{\hat{\bf x}} &amp;= \text{sigm}({\bf c} + {\bf (V \odot M^V)h(x)})  
\end{align*}
\]</span></p>
<p>The last problem is only find a way to construct masks <span class="math inline">\(\bf M^W\)</span>, <span class="math inline">\(\bf M^V\)</span> which sastify autoregressive property.<br>
Let <span class="math inline">\(m^{l}(k)\)</span> be the index assigned to hidden node <span class="math inline">\(k\)</span> in layer <span class="math inline">\(l\)</span>. The condition would be as follows:</p>
<ul>
<li>First, for each hidden layer <span class="math inline">\(l\)</span>, we sample <span class="math inline">\(m^{l}(k)\)</span> from a uniform distribution with range <span class="math inline">\([1,D−1]\)</span>. The index <span class="math inline">\(D\)</span> should be never used because nothing should depend on <span class="math inline">\(D^{th}\)</span> input</li>
<li>For a given node, it only connects to nodes in the previous layer that have an index less than or equal to its index.</li>
</ul>
<p><span class="math display">\[\ M^{W^l}_{k', k} =  \begin{cases}
                      1 \text{ if } m^l(k') \geq m^{l-1}(k)  \\
                      0 \text{ otherwise}
                    \end{cases}
\
\]</span> - The output mask is slightly different:</p>
<p><span class="math display">\[\ M^{V}_{d, k} = \begin{cases}
                    1 \text{ if } d &gt; m^{L}(k)  \\
                    0 \text{ otherwise}
                   \end{cases}
\
\]</span></p>
<p><img src="my_icons/MADE_archi.png" title="Figure 2: MADE" class="img-fluid"></p>
<p>In figure 2: - output 1 is not connected to anything. It will just be estimated with a single constant parameter derived from the bias node. Otherwise, output 2 is only connected to hiddens which are only connected to input 1. Finally, output 3 is connected to hiddens which come from input 1 and input 2</p>
<ul>
<li>On the other hand, input 3 is connected to nothing because no node should depend on it (autoregressive property).</li>
</ul>
</section>
<section id="discussion" class="level3">
<h3 class="anchored" data-anchor-id="discussion">Discussion</h3>
<ol type="1">
<li>Does ordering of input matters?</li>
</ol>
<p>Actually, there is no natural ordering input. We can shuffle the input dimensions, so that MADE is able to model any arbitrary ordering.</p>
<ol start="2" type="1">
<li>How can we generate new samples?</li>
</ol>
<p>Sampling steps: - Randomly generate vector x, set <span class="math inline">\(i=1\)</span> - Feed <span class="math inline">\(\bf x\)</span> into autoencoder and generate outputs <span class="math inline">\(\hat{\bf x}\)</span> for the network, set <span class="math inline">\(p =\bf \hat{x}_i\)</span> - Sample from a Bernoulli distribution with parameter p, set input <span class="math inline">\({\bf x}_i=Bernoulli(p)\)</span> - Increment <span class="math inline">\(i\)</span> and repeat steps 2-4 until <span class="math inline">\(i &gt; D\)</span>.</p>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<blockquote class="blockquote">
<p>The Pytorch code implementation of MADE is borrowed from this <a href="https://github.com/rll/deepul">repo</a>.<br>
In this example, We will build a network training on binarized MNIST dataset</p>
</blockquote>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T15:54:03.538877Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T15:54:02.968243Z&quot;}" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.utils <span class="im">import</span> make_grid</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data():</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="kw">lambda</span> x: (x <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">float</span>() <span class="co">#binarize image</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    train_dset <span class="op">=</span> MNIST(<span class="st">'data'</span>, transform<span class="op">=</span>transform, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    test_dset <span class="op">=</span> MNIST(<span class="st">'data'</span>, transform<span class="op">=</span>transform, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> data.DataLoader(train_dset, batch_size<span class="op">=</span><span class="dv">128</span>, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>                                   pin_memory<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    test_loader <span class="op">=</span> data.DataLoader(test_dset, batch_size<span class="op">=</span><span class="dv">128</span>, shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>                                  pin_memory<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_loader, test_loader</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_train_curves(epochs, train_losses, test_losses, title<span class="op">=</span><span class="st">''</span>):</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="dv">0</span>, epochs, <span class="bu">len</span>(train_losses))</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    plt.figure()</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    plt.plot(x, train_losses, label<span class="op">=</span><span class="st">'train_loss'</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_losses:</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        plt.plot(x, test_losses, label<span class="op">=</span><span class="st">'test_loss'</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_batch(batch_tensor, nrow<span class="op">=</span><span class="dv">8</span>, title<span class="op">=</span><span class="st">''</span>, figsize<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    grid_img <span class="op">=</span> make_grid(batch_tensor, nrow<span class="op">=</span>nrow)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>figsize)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    plt.imshow(grid_img.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>train_loader, test_loader <span class="op">=</span> load_data()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T15:54:03.550053Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T15:54:03.540271Z&quot;}" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, train_loader, optimizer):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x, _ <span class="kw">in</span> train_loader:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> model.nll(x)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> eval_loss(model, data_loader):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    total_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> x, _ <span class="kw">in</span> data_loader:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> model.nll(x)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss <span class="op">*</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        avg_loss <span class="op">=</span> total_loss <span class="op">/</span> <span class="bu">len</span>(data_loader.dataset)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> avg_loss.item()</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_epochs(model, train_loader, test_loader, train_args):</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    epochs, lr <span class="op">=</span> train_args[<span class="st">'epochs'</span>], train_args[<span class="st">'lr'</span>]</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    train_losses, test_losses <span class="op">=</span> [], []</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> model.sample(<span class="dv">64</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    visualize_batch(samples, title<span class="op">=</span><span class="ss">f'Intialization'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> train(model, train_loader, optimizer)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> eval_loss(model, train_loader)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        train_losses.append(train_loss)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> test_loader <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">=</span> eval_loss(model, test_loader)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>            test_losses.append(test_loss)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> model.sample(<span class="dv">64</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:    </span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss"> Test Loss: </span><span class="sc">{</span>test_losses[epoch] <span class="op">/</span> np<span class="sc">.</span>log(<span class="dv">2</span>)<span class="sc">:.4f}</span><span class="ss"> bits/dim'</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>            visualize_batch(samples, title<span class="op">=</span><span class="ss">f'Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> test_loader <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Test Loss'</span>, test_loss)</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    plot_train_curves(epochs, train_losses, test_losses, title<span class="op">=</span><span class="st">'Training Curve'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T15:54:04.693250Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T15:54:04.676391Z&quot;}" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MaskedLinear(nn.Linear):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" same as Linear except has a configurable mask on the weights """</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features, out_features, bias<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(in_features, out_features, bias)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'mask'</span>, torch.ones(out_features, in_features))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> set_mask(<span class="va">self</span>, mask):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mask.data.copy_(torch.from_numpy(mask.astype(np.uint8).T))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.linear(<span class="bu">input</span>, <span class="va">self</span>.mask <span class="op">*</span> <span class="va">self</span>.weight, <span class="va">self</span>.bias)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MADE(nn.Module):</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, device):</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nin <span class="op">=</span> <span class="dv">784</span> <span class="co">#28 * 28</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nout <span class="op">=</span> <span class="dv">784</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_sizes <span class="op">=</span> [<span class="dv">512</span>, <span class="dv">512</span>, <span class="dv">512</span>]</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># define a simple MLP neural net</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> []</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        hs <span class="op">=</span> [<span class="va">self</span>.nin] <span class="op">+</span> <span class="va">self</span>.hidden_sizes <span class="op">+</span> [<span class="va">self</span>.nout]</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> h0, h1 <span class="kw">in</span> <span class="bu">zip</span>(hs, hs[<span class="dv">1</span>:]):</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.net.extend([</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>                MaskedLinear(h0, h1),</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>                nn.ReLU(),</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            ])</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net.pop()  <span class="co"># pop the last ReLU for the output layer</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(<span class="op">*</span><span class="va">self</span>.net).to(device)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.m <span class="op">=</span> {}</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.create_mask()  <span class="co"># builds the initial self.m connectivity</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_mask(<span class="va">self</span>):</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        L <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.hidden_sizes)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample uniform distribution the order of the inputs and the connectivity of all neurons</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.m[<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> np.arange(<span class="va">self</span>.nin)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(L):</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.m[l] <span class="op">=</span> np.random.randint(<span class="va">self</span>.m[l <span class="op">-</span> <span class="dv">1</span>].<span class="bu">min</span>(), <span class="va">self</span>.nin <span class="op">-</span> <span class="dv">1</span>, size<span class="op">=</span><span class="va">self</span>.hidden_sizes[l])</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># construct the mask matrices</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        masks <span class="op">=</span> [<span class="va">self</span>.m[l <span class="op">-</span> <span class="dv">1</span>][:, <span class="va">None</span>] <span class="op">&lt;=</span> <span class="va">self</span>.m[l][<span class="va">None</span>, :] <span class="cf">for</span> l <span class="kw">in</span> <span class="bu">range</span>(L)]</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        masks.append(<span class="va">self</span>.m[L <span class="op">-</span> <span class="dv">1</span>][:, <span class="va">None</span>] <span class="op">&lt;</span> <span class="va">self</span>.m[<span class="op">-</span><span class="dv">1</span>][<span class="va">None</span>, :])</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># set the masks in all MaskedLinear layers</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [l <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.net.modules() <span class="cf">if</span> <span class="bu">isinstance</span>(l, MaskedLinear)]</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l, m <span class="kw">in</span> <span class="bu">zip</span>(layers, masks):</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>            l.set_mask(m)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> nll(<span class="va">self</span>, x):</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>).to(<span class="va">self</span>.device) <span class="co"># Flatten image</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.net(x)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.binary_cross_entropy_with_logits(logits, x)</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, n):</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.zeros(n, <span class="dv">784</span>).to(<span class="va">self</span>.device)</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">784</span>):</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> <span class="va">self</span>.net(samples)[:, i]</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>                probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>                samples[:, i] <span class="op">=</span> torch.bernoulli(probs)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            samples <span class="op">=</span> samples.view(n, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> samples.cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-05-28T06:09:20.519767Z&quot;,&quot;start_time&quot;:&quot;2020-05-28T06:09:16.702882Z&quot;}" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> {<span class="st">'epochs'</span>: <span class="dv">20</span>, <span class="st">'lr'</span>: <span class="fl">0.01</span>}</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MADE(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-05-22T10:02:23.209840Z&quot;,&quot;start_time&quot;:&quot;2020-05-22T10:00:01.504527Z&quot;}" data-execution_count="66">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>train_epochs(model, train_loader, test_loader, train_args)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Test Loss: 0.2613 bits/dim
Epoch 5 Test Loss: 0.2191 bits/dim
Epoch 10 Test Loss: 0.2124 bits/dim
Epoch 15 Test Loss: 0.2096 bits/dim
Test Loss 0.14515839517116547</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-6.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-6-output-7.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="pixelcnn" class="level2">
<h2 class="anchored" data-anchor-id="pixelcnn">PixelCNN</h2>
<p>PixelCNN is a deep autoregressive generative model for images. Let’s consider an image of size <span class="math inline">\(n×n\)</span>, each pixel in image is a data point <span class="math inline">\(\bf x=\big\{{\bf x_1,…,x_{n^2}}\big\}\)</span>. The model starts generating pixels from the top left corner, from left to right and top to bottom (<a href="https://en.wikipedia.org/wiki/Raster_scan">raster scanning</a>).</p>
<p><img src="my_icons/pixel_cnn.png" title="Figure 3: PixelCNN. Source[3]" class="img-fluid"></p>
<p>Each pixel <span class="math inline">\(\bf{x}_i\)</span> is in turn jointly determined by three values,one for each of the color channels Red, Green and Blue (RGB). Each of the colors is thus conditioned on the other channels as well as on all the previously generated pixels. <span class="math display">\[\mathbf p( \mathbf x_i| \mathbf x_{&lt;i}) = \mathbf p(\mathbf x_{i,R}|\mathbf x_{&lt;i}). \mathbf p(x_{i,G}|\mathbf x_{&lt;i},\mathbf x_{i,R}). \mathbf p(x_{i,B}|\mathbf x_{&lt;i},\mathbf x_{i,R},\mathbf x_{i,G})\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Along with PixelCNN, the paper authors also proposed PixelRNN with the same analogy as PixelCNN. However, PixelRNN with sequential dependency between LSTM states is very expensive for the computation. So this method will not be detailed in this blog. Check the <a href="https://arxiv.org/pdf/1601.06759.pdf">paper</a> if you are interested in it.</p>
</div>
</div>
<section id="masked-spatial-convolution" class="level3">
<h3 class="anchored" data-anchor-id="masked-spatial-convolution">Masked spatial convolution</h3>
<p>The masked use the convolution filter to slide over image which multiplies each element and sums them together to produce a single response. However, we cannot use this filter because a generated pixel should not know the intensities of future pixel values. To counter this issue, we use a mask on top of the filter to only choose prior pixels and zeroing the future pixels to negate them from calculation.</p>
<p><img src="https://wiki.math.uwaterloo.ca/statwiki/images/thumb/f/f0/masking1.png/320px-masking1.png" title="Figure 3 : Masked spatial convolution. [Source](https://wiki.math.uwaterloo.ca/statwiki/index.php?title=STAT946F17/Conditional_Image_Generation_with_PixelCNN_Decoders)" class="img-fluid"></p>
</section>
<section id="blind-spot" class="level3">
<h3 class="anchored" data-anchor-id="blind-spot">Blind spot</h3>
<p>PixelCNN masking has one problem: <strong>blind spot</strong> in receptive field because the capturing of receptive field by a CNN proceed in a triangular fashion.</p>
<p><img src="my_icons/blind_spot_pixelCNN.png" title="Figure 4: Blind spot in PixelCNN" class="img-fluid"></p>
<p>In order to address the blind spot, the authors use two filters (horizontal and vertical stacks) in conjunction to allow for capturing the whole receptive ﬁeld. - <strong>Vertical stack</strong>: conditions on all the pixels in the rows above the current pixel. It doesn’t have any masking, allow the receptive field to grow in a rectangular fashion without any blind spot - <strong>Horizontal stack</strong>: conditions on the current row and takes as input the output of previous layer as well as of the vertical stack.</p>
<p><img src="https://wiki.math.uwaterloo.ca/statwiki/images/thumb/4/48/vh_stack.png/799px-vh_stack.png" title="Figure 5: Vertical stack and horizontal stack to tackle blind spot problem" class="img-fluid"></p>
</section>
<section id="gated-pixelcnn" class="level3">
<h3 class="anchored" data-anchor-id="gated-pixelcnn">Gated PixelCNN</h3>
<p>The PixelCNN only takes into consideration the neighborhood region and the depth of the convolution layers to make its predictions. To improve the performance of PixelCNN, the authors replaced the rectified linear units between the masked convolutions with the following gated activation function in order to model more complex interactions: <span class="math display">\[\mathbf{y} = \tanh (\mathbf W_{k,f} \ast \mathbf{x}) \odot \sigma (\mathbf W_{k,g} \ast \mathbf{x})\]</span></p>
<p>where:<br>
<span class="math inline">\(*\)</span> is the convolutional operator.<br>
<span class="math inline">\(\odot\)</span> is the element-wise product.<br>
<span class="math inline">\(\sigma\)</span> is the sigmoid non-linearity<br>
<span class="math inline">\(k\)</span> is the number of the layer<br>
<span class="math inline">\(tanh(W_{k,f} \ast \mathbf x)\)</span> is a classical convolution with tanh activation function.<br>
<span class="math inline">\(\sigma(W_{k,g} \ast \mathbf x)\)</span> are the gate values (0 = gate closed, 1 = gate open).<br>
<span class="math inline">\(W_{k,f}\)</span> and <span class="math inline">\(W_{k,g}\)</span> are learned weights.<br>
<span class="math inline">\(f, g\)</span> are the different feature maps</p>
<p>A gated block is represented in Figure 6. There are 2 things to notice here: 1. the vertical stack contributes to the horizontal stack with the <span class="math inline">\(1\times1\)</span> convolution while vertical stack should not access any information horizontal stack has - otherwise it will have access to pixels it shouldn’t see. However, the vertical stack can be vertically connected as it predicts pixel following those in the vertical stack. 2. The convolutions with <span class="math inline">\(W_f\)</span> and <span class="math inline">\(W_g\)</span> are not combined into a single operation (which is essentially the masked convolution) to increase parallelization. The parallelization splits the <span class="math inline">\(2p\)</span> features maps into two groups of <span class="math inline">\(p\)</span></p>
<p><img src="https://wiki.math.uwaterloo.ca/statwiki/images/thumb/6/61/gated_block.png/800px-gated_block.png" title="Figure 6: A gated PixelCNN block" class="img-fluid" alt="Source">.</p>
</section>
<section id="conditional-pixelcnn" class="level3">
<h3 class="anchored" data-anchor-id="conditional-pixelcnn">Conditional PixelCNN</h3>
<p>Sometimes we want to integrate some high-level information before feed the network, for example provising an image to the network with the associated classes in CIFAR datasets. During training we feed image as well as class to our network to make sure network would learn to incorporate that information as well. During inference we can specify what class our output image should belong to.</p>
<p>For a conditional PixelCNN, we represent a provided high-level image description as a latent vector <span class="math inline">\(\mathbf h\)</span>, wherein the purpose of the latent vector is to model the conditional distribution <span class="math inline">\(p(\mathbf{x} \vert \mathbf{h})\)</span> such that we get a probability as to if the images suites this description. The conditional PixelCNN models based on the following distribution: <span class="math display">\[p(\mathbf{x} \vert \mathbf{h}) = \prod_{i=1}^{n^2} p(x_i \vert x_1, \cdots, x_{i-1}, \mathbf{h})\]</span></p>
<p>Add terms <span class="math inline">\(\mathbf h\)</span> before the non-linearities:</p>
<p><span class="math display">\[ \mathbf{y} = \tanh (W_{k,f} \ast \mathbf{x}  {+ V_{k,f}^\top \mathbf{h}} ) \odot \sigma (W_{k,g} \ast \mathbf{x} {+ V_{k,g}^\top \mathbf{h} })\]</span></p>
<ul>
<li>If the latent vector <span class="math inline">\(\mathbf h\)</span> is a one-hot encoding vector that provides the class labels, which is equivalent to the adding a class dependent bias at every layer. So, the conditioning is dependent on “what should the image contain” rather than the location of contents in the image.</li>
<li>To add the location dependency to the model, we use a transposed convolution to map <span class="math inline">\(\mathbf h\)</span> to a spatial representation <span class="math inline">\(s=deconv(\mathbf h)\)</span> to produce the output <span class="math inline">\(\mathbf s\)</span> of the same shape as the image:</li>
</ul>
<p><span class="math display">\[\mathbf{y} = \tanh (W_{k,f} \ast \mathbf{x}  {+ V_{k,f} \ast \mathbf{s}} ) \odot \sigma (W_{k,g} \ast \mathbf{x} {+ V_{k,g} \ast \mathbf{s} })\]</span></p>
</section>
<section id="implementation-1" class="level3">
<h3 class="anchored" data-anchor-id="implementation-1">Implementation</h3>
<blockquote class="blockquote">
<p>The Pytorch code implementation of Gated PixelCNN is borrowed from this <a href="https://github.com/rll/deepul">repo</a>.</p>
</blockquote>
<section id="pixelcnn-with-blind-spot" class="level4">
<h4 class="anchored" data-anchor-id="pixelcnn-with-blind-spot">PixelCNN with blind spot</h4>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T06:34:34.176454Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T06:34:34.159223Z&quot;}" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MaskConv2d(nn.Conv2d):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, mask_type, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> mask_type <span class="op">==</span> <span class="st">'A'</span> <span class="kw">or</span> mask_type <span class="op">==</span> <span class="st">'B'</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'mask'</span>, torch.zeros_like(<span class="va">self</span>.weight))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.create_mask(mask_type)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.conv2d(<span class="bu">input</span>, <span class="va">self</span>.weight <span class="op">*</span> <span class="va">self</span>.mask, <span class="va">self</span>.bias, <span class="va">self</span>.stride,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                        <span class="va">self</span>.padding, <span class="va">self</span>.dilation, <span class="va">self</span>.groups)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> create_mask(<span class="va">self</span>, mask_type):</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.kernel_size[<span class="dv">0</span>]</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mask[:, :, :k <span class="op">//</span> <span class="dv">2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mask[:, :, k <span class="op">//</span> <span class="dv">2</span>, :k <span class="op">//</span> <span class="dv">2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask_type <span class="op">==</span> <span class="st">'B'</span>:</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mask[:, :, k <span class="op">//</span> <span class="dv">2</span>, k <span class="op">//</span> <span class="dv">2</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PixelCNN(nn.Module):</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, device):</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> [MaskConv2d(<span class="st">'A'</span>, <span class="dv">1</span>, <span class="dv">64</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="dv">3</span>), nn.ReLU()]</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>            model.extend([MaskConv2d(<span class="st">'B'</span>, <span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="dv">3</span>), nn.ReLU()])</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        model.append(MaskConv2d(<span class="st">'B'</span>, <span class="dv">64</span>, <span class="dv">1</span>, <span class="dv">7</span>,padding<span class="op">=</span><span class="dv">3</span>))</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(<span class="op">*</span>model).to(device)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> nll(<span class="va">self</span>, x):</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(<span class="va">self</span>.device)</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.net(x)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.binary_cross_entropy_with_logits(logits, x)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, n):</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.zeros(n, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>).to(<span class="va">self</span>.device)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>                    logits <span class="op">=</span> <span class="va">self</span>.net(samples)[:, :, r, c]</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>                    probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>                    samples[:, :, r, c] <span class="op">=</span> torch.bernoulli(probs)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> samples.cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T06:35:13.473141Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T06:35:09.718165Z&quot;}" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> {<span class="st">'epochs'</span>: <span class="dv">21</span>, <span class="st">'lr'</span>: <span class="fl">0.0002</span>}</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> PixelCNN(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T06:45:31.213577Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T06:35:22.893402Z&quot;}" data-execution_count="9">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>train_epochs(model, train_loader, test_loader, train_args)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Test Loss: 0.1629 bits/dim
Epoch 10 Test Loss: 0.1217 bits/dim
Epoch 20 Test Loss: 0.1177 bits/dim
Test Loss 0.08157001435756683</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-9-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-9-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-9-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-9-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="pixelcnn-without-blind-spot" class="level4">
<h4 class="anchored" data-anchor-id="pixelcnn-without-blind-spot">PixelCNN without blind spot</h4>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T08:29:41.699869Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T08:29:41.620450Z&quot;}" data-execution_count="80">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> HoriVertStackConv2d(nn.Module):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, mask_type, in_channels, out_channels, k<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>, </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                 gated<span class="op">=</span><span class="va">False</span>, residual_horizontal<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        gm <span class="op">=</span> <span class="dv">2</span> <span class="cf">if</span> gated <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gated <span class="op">=</span> gated</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_channels <span class="op">=</span> out_channels</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vertical <span class="op">=</span> nn.Conv2d(in_channels, gm <span class="op">*</span> out_channels, kernel_size<span class="op">=</span>k,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>                                  padding<span class="op">=</span>padding, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.horizontal <span class="op">=</span> nn.Conv2d(in_channels, gm <span class="op">*</span> out_channels, kernel_size<span class="op">=</span>(<span class="dv">1</span>, k),</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>                                    padding<span class="op">=</span>(<span class="dv">0</span>, padding), bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vtohori <span class="op">=</span> nn.Conv2d(gm <span class="op">*</span> out_channels, gm <span class="op">*</span> out_channels, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.horizontal_output <span class="op">=</span> nn.Conv2d(in_channels , out_channels, <span class="dv">1</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.residual_horizontal <span class="op">=</span> residual_horizontal</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'vmask'</span>, <span class="va">self</span>.vertical.weight.data.clone())</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'hmask'</span>, <span class="va">self</span>.horizontal.weight.data.clone())</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vmask.fill_(<span class="dv">1</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hmask.fill_(<span class="dv">1</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero the bottom half rows of the vmask</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vmask[:, :, k <span class="op">//</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>:, :] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero the right half of the hmask</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hmask[:, :, :, k <span class="op">//</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">1</span>:] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask_type <span class="op">==</span> <span class="st">'A'</span>:</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hmask[:, :, :, k <span class="op">//</span> <span class="dv">2</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _gated(<span class="va">self</span>, x):</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.tanh(x[:, :<span class="va">self</span>.out_channels]) <span class="op">*</span> torch.sigmoid(x[:, <span class="va">self</span>.out_channels:])</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> down_shift(<span class="va">self</span>, x):</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x[:, :, :<span class="op">-</span><span class="dv">1</span>, :]</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        pad <span class="op">=</span> nn.ZeroPad2d((<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pad(x)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>        vx, h <span class="op">=</span> x.chunk(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.vertical.weight.data <span class="op">*=</span> <span class="va">self</span>.vmask</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.horizontal.weight.data <span class="op">*=</span> <span class="va">self</span>.hmask</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>        vx <span class="op">=</span> <span class="va">self</span>.vertical(vx)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>        hx <span class="op">=</span> <span class="va">self</span>.horizontal(h)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Allow horizontal stack to see information from vertical stack</span></span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        hx <span class="op">=</span> hx <span class="op">+</span> <span class="va">self</span>.vtohori(<span class="va">self</span>.down_shift(vx))</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.gated:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>            vx <span class="op">=</span> <span class="va">self</span>._gated(vx)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>            hx <span class="op">=</span> <span class="va">self</span>._gated(hx)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.residual_horizontal:</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>            h <span class="op">=</span> <span class="va">self</span>.horizontal_output(h)</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>            hx <span class="op">=</span> h <span class="op">+</span> hx</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cat((vx, hx), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a><span class="co"># PixelCNN using horizontal and vertical stacks to fix blind-spot</span></span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GatedHoriVertStackPixelCNN(nn.Module):</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> <span class="st">'HoriVertStackPixelCNN'</span></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_layers, device):</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> [HoriVertStackConv2d(<span class="st">'A'</span>, <span class="dv">1</span>, <span class="dv">64</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="dv">3</span>), nn.ReLU()]</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>            model.extend([HoriVertStackConv2d(<span class="st">'B'</span>, <span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">7</span>, padding<span class="op">=</span><span class="dv">3</span>), </span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>                          nn.ReLU()])</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>        model.append(HoriVertStackConv2d(<span class="st">'B'</span>, <span class="dv">64</span>, <span class="dv">1</span>, <span class="dv">7</span>,padding<span class="op">=</span><span class="dv">3</span>))</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(<span class="op">*</span>model).to(device)</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(<span class="va">self</span>.device)</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.net(torch.cat((x, x), dim<span class="op">=</span><span class="dv">1</span>)).chunk(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)[<span class="dv">1</span>]</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> nll(<span class="va">self</span>, x):</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(<span class="va">self</span>.device)</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.binary_cross_entropy_with_logits(logits, x)</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, n):</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.zeros(n, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>) <span class="co">#here we sample only one channel instead of three for simplicity</span></span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>                    logits <span class="op">=</span> <span class="va">self</span>(samples)[:, :, r, c]</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>                    probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>                    samples[:, :, r, c] <span class="op">=</span> torch.bernoulli(probs)</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> samples.cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T08:29:42.563525Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T08:29:42.526966Z&quot;}" data-execution_count="81">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> {<span class="st">'epochs'</span>: <span class="dv">21</span>, <span class="st">'lr'</span>: <span class="fl">0.0002</span>}</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GatedHoriVertStackPixelCNN(<span class="dv">4</span>, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T08:45:48.141974Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T08:29:43.100292Z&quot;}" data-execution_count="82">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>train_epochs(model, train_loader, test_loader, train_args)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Test Loss: 0.3259 bits/dim
Epoch 10 Test Loss: 0.3033 bits/dim
Epoch 20 Test Loss: 0.3007 bits/dim
Test Loss 0.20846164226531982</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-12-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-12-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-12-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-12-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
</section>
<section id="pixelcnn-1" class="level2">
<h2 class="anchored" data-anchor-id="pixelcnn-1">PixelCNN++</h2>
<p>PixelCNN typically consists of a stack of masked convolutional layers that takes an <span class="math inline">\(N \times N \times 3\)</span> image as input and produces <span class="math inline">\(N \times N \times 3 \times 256\)</span> (probability of pixel intensity) predictions as output. The softmax layer in PixelCNN to compute the conditional distribution of a sub-pixel is a full of 256-softmax. There are 2 issues with this approache: First, it is very costly in terms of memory. Second, it is missing the continuity property data. It means that the model does not know that a value of 128 is close to a value of 127 or 129 but no different than 255 for instance.</p>
<p>To address this issue, the paper authors came up with the new model including following modifications compared to PixelCNN:</p>
<p><strong>Discretized logistic mixture likelihood</strong></p>
<ul>
<li>For each sub-pixel, generate a continuous distribution <span class="math inline">\(ν\)</span> representing the colour intensity instead of discrete distribution. For example, ν could be a mixture of <a href="https://en.wikipedia.org/wiki/Logistic_distribution">logistic distribution</a> parameterized by <span class="math inline">\(\mu,s\)</span> and the mixture weights <span class="math inline">\(\pi\)</span>. <span class="math display">\[
\nu \sim \sum_{i=1}^K \pi_i logistic(\mu_i, s_i)
\]</span></li>
<li>We then convert this intensity to a mass function by assigning regions of it to the 0 to 255 pixels:</li>
</ul>
<p><span class="math display">\[
\ P(x|\mu,s) =
    \begin{cases}
        \sigma(\frac{x-\mu+0.5}{s}) &amp; \text{for } x = 0 \\
        \sigma(\frac{x-\mu+0.5}{s}) - \sigma(\frac{x-\mu-0.5}{s})
            &amp; \text{for } 0 &lt; x &lt; 255 \\
        1 - \sigma(\frac{x-\mu-0.5}{s}) &amp; \text{for } x = 255
    \end{cases}
\
\]</span> where <span class="math inline">\(\sigma\)</span> is the sigmoid function.</p>
<p><strong>Conditioning on whole pixels</strong></p>
<p>PixelCNN factorizes the model over the 3 sub pixels according to the color(RGB) which however, complicates the model. The dependency between color channels of a pixel is relatively simple and doesn’t require a deep model to train. Therefore, it is better to condition on whole pixels instead of separate colors and then output joint distributions over all 3 channels of the predicted pixel. - We first predict the red channel using a discretized mixture of logistic - Next, we predict the green channel using a predictive distribution of the same form. Here we allow the means of the mixture components to linearly depend on the value of the red sub-pixel.<br>
- Finally, we model the blue channel in the same way, where we again only allow linear dependency on the red and green channels.</p>
<p><strong>Downsampling versus dilated convolution</strong></p>
<p>The PixelCNN uses convolutions with small receptive field which is good at capturing local dependencies, but not necessarily at modeling long range structure. To overcome this, we downsample the layers by using convolutions of stride 2. Downsampling reduces input size and thus improves relative size of receptive field which leads to some loss of information but it can be compensated by adding extra short-cut connections.</p>
<p><strong>Adding short-cut connections</strong></p>
<p>The idea is pretty the same as <a href="https://arxiv.org/abs/1505.04597">Unet</a> model by introducing additional short-cut connections into the model to recover the losed informations from lower layers to higher layers of the model.</p>
<p><strong>Regularization using dropout</strong> The PixelCNN model is powerful enough to overfit on training data, leads to lower perceptual quality of images while generating data. One effective way of regularizing neural networks is <a href="http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">dropout (Srivas-tava et al., 2014)</a>.</p>
</section>
<section id="wavenet" class="level2">
<h2 class="anchored" data-anchor-id="wavenet">WaveNet</h2>
<p>All the examples we’ve seen so far are images generation which is 2D data. The technique of autoregressive generative model can also be applied to 1D data such as audio or text. We will take a look on similar approaches which are based on PixelCNN idea in generating raw audio waveforms, which are signals with very high temporal resolution, at least 16,000 samples per second. One of the most popular applications of this method is <strong>text-to-speech</strong> where we have to generate a audio from text input.</p>
<p>Similarly to PixelCNNs explained above, the joint probability of a waveform <span class="math inline">\(\bf x=\{x_1,...,x_T\}\)</span> is factorised as a product of conditional probabilities of each audio sample <span class="math inline">\(\bf x_t\)</span> which is conditioned on the samples at all previous timesteps. The conditional probability distribution is also modelled by a stack of convolutional layers.</p>
<p>To take care of autoregressive property, the wavenet model is using <strong>casual convolution</strong>. At training time, the conditional predictions for all timesteps can be made in parallel because all timesteps of ground truth <span class="math inline">\(\bf x\)</span> are known. When generating with the model, the predictions are sequential: after each sample is predicted, it is fed back into the network to predict the next sample. However, one of the problems of causal convolutions is that they require many layers, or large filters to increase the receptive field. To mitigate this problem, Wavenet used <strong>dilated convolution</strong></p>
<p><img src="my_icons/casual_conv.png" title="Figure 7: Casual convolution" class="img-fluid"></p>
<section id="dilated-convolution" class="level3">
<h3 class="anchored" data-anchor-id="dilated-convolution">Dilated convolution</h3>
<p>A dilated convolution (also called <em>à trous</em>, or convolution with holes) is a convolution where the filter is applied over an area larger than its length by skipping input values with a certain step. This technique is broadly used to increase the receptive field by orders of magnitude, without greatly increasing computational cost. In computer vision, we’ve seen it in semantic segmentation model.</p>
<p>A dilated convolution effectively allows the network to operate ona coarser scale than with a normal convolution. This is similar to pooling or strided convolutions, but here the output has the same size as the input.</p>
<p><img src="my_icons/dilated_conv.png" title="Figure 8: Dilated 2D Convolution" class="img-fluid"></p>
<p>The intuition is that exponentially increasing the dilation factor results in exponential receptive field growth with depth. So stack these dilated convolutions blocks further increases the model capacity and the receptive field size of the model.</p>
<p><img src="my_icons/dilated_conv_1d.png" title="Figure 9: Dilated convolution in Wavenet. Source[11]" class="img-fluid"></p>
<p>Except for the dilated convolution, the Wavenet model is very similar to PixelCNN such as gated activation units technique.</p>
</section>
<section id="softmax-distribution" class="level3">
<h3 class="anchored" data-anchor-id="softmax-distribution">Softmax distribution</h3>
<p>The raw audio output is stored as a sequence of 16-bit scalar values (one per time step), thus the softmax output is 2^16=65,536 probabilities per timestep. WaveNet applies a <a href="https://en.wikipedia.org/wiki/%CE%9C-law_algorithm">μ-law companding transformation</a> to the data and then quantize it to 256 possible values:</p>
<p><span class="math display">\[f(\bf{x}_t) = \text{sign} (x_t) \frac{\ln(1 + \mu |x_t|)}{\ln(1 + \mu)}\]</span> where <span class="math inline">\(x_t \in (−1,1), \mu = 255\)</span></p>
</section>
<section id="fast-wavenet-generation" class="level3">
<h3 class="anchored" data-anchor-id="fast-wavenet-generation">Fast WaveNet Generation</h3>
<p>With the implemenentation of Wavenet in Figure 9, since the computation forms a binary tree, the overall computation time for a single output is <span class="math inline">\(O(2^L)\)</span>, where <span class="math inline">\(L\)</span> is the number of layers in the network. When <span class="math inline">\(L\)</span> is large, this is extremely undesirable. This <a href="https://arxiv.org/pdf/1611.09482.pdf">paper</a> proposed approach removes redundant convolution operations by caching previous calculations instead of recomputing many variables that have already been computed for previous samples, thereby reducing the complexity to <span class="math inline">\(O(L)\)</span> time.</p>
<p>The below figure shows the model with 2 convolutional and 2 transposed convolutional layers with strid of 2, wherein blue dots indicate the cached states and orange bots are computed in the current step.</p>
<p><img src="my_icons/fast_generation.png" title="Figure 10: Fast generation for a network with strided convolutions" class="img-fluid"></p>
</section>
<section id="implementation-2" class="level3">
<h3 class="anchored" data-anchor-id="implementation-2">Implementation</h3>
<blockquote class="blockquote">
<p>The Pytorch code implementation of WaveNet is borrowed from this <a href="https://github.com/ryujaehun/wavenet">repo</a>.</p>
</blockquote>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T16:07:26.741627Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T16:07:26.720794Z&quot;}" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> append_location(x, device):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Pixel Location Appended as Features</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> torch.arange(<span class="dv">28</span>).<span class="bu">float</span>() <span class="op">/</span> <span class="dv">27</span>  <span class="co"># Scale to [0, 1]</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    locs <span class="op">=</span> torch.stack(torch.meshgrid(idxs, idxs), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    locs <span class="op">=</span> locs.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>).contiguous().unsqueeze(<span class="dv">0</span>).repeat(x.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    locs <span class="op">=</span> locs.to(device)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.cat((x, locs), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DilatedCausalConv1d(nn.Module):</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Dilated Causal Convolution for WaveNet"""</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, mask_type, in_channels, out_channels, dilation<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DilatedCausalConv1d, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Conv1d(in_channels, out_channels,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>                              kernel_size<span class="op">=</span><span class="dv">2</span>, dilation<span class="op">=</span>dilation, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dilation <span class="op">=</span> dilation</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mask_type <span class="op">=</span> mask_type</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> mask_type <span class="kw">in</span> [<span class="st">'A'</span>, <span class="st">'B'</span>]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.mask_type <span class="op">==</span> <span class="st">'A'</span>:</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.conv(F.pad(x, [<span class="dv">2</span>, <span class="dv">0</span>]))[:, :, :<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.conv(F.pad(x, [<span class="va">self</span>.dilation, <span class="dv">0</span>]))</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResidualBlock(nn.Module):</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" Gated Unit Activation"""</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, res_channels, dilation):</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResidualBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dilated <span class="op">=</span> DilatedCausalConv1d(<span class="st">'B'</span>, res_channels, <span class="dv">2</span> <span class="op">*</span> res_channels, dilation<span class="op">=</span>dilation)</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_res <span class="op">=</span> nn.Conv1d(res_channels, res_channels, <span class="dv">1</span>)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.dilated(x)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># PixelCNN gate</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>        o1, o2 <span class="op">=</span> output.chunk(<span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.tanh(o1) <span class="op">*</span> torch.sigmoid(o2)</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.conv_res(output) <span class="co"># Residual network</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WaveNet(nn.Module):</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, device, append_loc<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(WaveNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>        in_channels <span class="op">=</span> <span class="dv">3</span> <span class="cf">if</span> append_loc <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>        out_channels <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>        res_channels <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>        layer_size <span class="op">=</span> <span class="dv">5</span> <span class="co"># Largest dilation is 16</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>        stack_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.causal <span class="op">=</span> DilatedCausalConv1d(<span class="st">'A'</span>, in_channels, res_channels, dilation<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res_stack <span class="op">=</span> nn.Sequential(<span class="op">*</span><span class="bu">sum</span>([[ResidualBlock(res_channels, <span class="dv">2</span> <span class="op">**</span> i)</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>                                         <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(layer_size)] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(stack_size)], []))</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.out_conv <span class="op">=</span> nn.Conv1d(res_channels, out_channels, <span class="dv">1</span>)</span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.append_loc <span class="op">=</span> append_loc</span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.append_loc:</span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> append_location(x, <span class="va">self</span>.device)</span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> x.view(batch_size, <span class="op">-</span><span class="dv">1</span>, <span class="dv">784</span>)</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.causal(output)</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.res_stack(output)</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.out_conv(output)</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output.view(batch_size, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> nll(<span class="va">self</span>, x):</span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(<span class="va">self</span>.device)</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.binary_cross_entropy_with_logits(logits, x)</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, n):</span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a>            samples <span class="op">=</span> torch.zeros(n, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>).to(<span class="va">self</span>.device)</span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a>                    logits <span class="op">=</span> <span class="va">self</span>(samples)[:, :, r, c]</span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a>                    probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a>                    samples[:, :, r, c] <span class="op">=</span> torch.bernoulli(probs)</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> samples.cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T15:59:18.750090Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T15:59:18.715657Z&quot;}" data-execution_count="10">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> {<span class="st">'epochs'</span>: <span class="dv">21</span>, <span class="st">'lr'</span>: <span class="fl">0.0002</span>}</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> WaveNet(device).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T16:07:26.719290Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T15:59:19.068037Z&quot;}" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>train_epochs(model, train_loader, test_loader, train_args)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Test Loss: 0.1659 bits/dim
Epoch 10 Test Loss: 0.1265 bits/dim
Epoch 20 Test Loss: 0.1240 bits/dim
Test Loss 0.08596379309892654</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-15-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-15-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-15-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-15-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="self-attention-autoregressive-model" class="level2">
<h2 class="anchored" data-anchor-id="self-attention-autoregressive-model">Self-Attention Autoregressive Model</h2>
<p>Recently, we’ve witnessed a tremendous application of Transformer models in NLP. The multi-head self-attention idea behind all these models is approaching many other fields. Explaining in details how it works is out of scope of this post. If you are curious about it, I recommend to take a look on this wonderful <a href="https://jalammar.github.io/illustrated-transformer/">blog</a>.</p>
<p>The idea of using Transformer on autoregressive generative model is similar with RNN generative model. However, the Transformer is the transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution.</p>
<section id="implementation-3" class="level3">
<h3 class="anchored" data-anchor-id="implementation-3">Implementation</h3>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T16:28:54.403794Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T16:28:54.339342Z&quot;}" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PositionalEncoding(nn.Module):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_hid, n_position<span class="op">=</span><span class="dv">784</span>):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(PositionalEncoding, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Not a parameter</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'pos_table'</span>, <span class="va">self</span>._get_sinusoid_encoding_table(n_position, d_hid))</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_sinusoid_encoding_table(<span class="va">self</span>, n_position, d_hid):</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">''' Sinusoid position encoding table '''</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> get_position_angle_vec(position):</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [position <span class="op">/</span> np.power(<span class="dv">10000</span>, <span class="dv">2</span> <span class="op">*</span> (hid_j <span class="op">//</span> <span class="dv">2</span>) <span class="op">/</span> d_hid) <span class="cf">for</span> hid_j <span class="kw">in</span> <span class="bu">range</span>(d_hid)]</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        sinusoid_table <span class="op">=</span> np.array([get_position_angle_vec(pos_i) <span class="cf">for</span> pos_i <span class="kw">in</span> <span class="bu">range</span>(n_position)])</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>        sinusoid_table[:, <span class="dv">0</span>::<span class="dv">2</span>] <span class="op">=</span> np.sin(sinusoid_table[:, <span class="dv">0</span>::<span class="dv">2</span>])  <span class="co"># dim 2i</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        sinusoid_table[:, <span class="dv">1</span>::<span class="dv">2</span>] <span class="op">=</span> np.cos(sinusoid_table[:, <span class="dv">1</span>::<span class="dv">2</span>])  <span class="co"># dim 2i+1</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.FloatTensor(sinusoid_table).unsqueeze(<span class="dv">0</span>) <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> <span class="va">self</span>.pos_table[:, :x.size(<span class="dv">1</span>)].clone().detach()</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ScaledDotProductAttention(nn.Module):</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' Scaled Dot-Product Attention '''</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, temperature, attn_dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.temperature <span class="op">=</span> temperature</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(attn_dropout)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, q, k, v, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        attn <span class="op">=</span> torch.matmul(q <span class="op">/</span> <span class="va">self</span>.temperature, k.transpose(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>            attn <span class="op">=</span> attn.masked_fill(mask <span class="op">==</span> <span class="dv">0</span>, <span class="op">-</span><span class="fl">1e9</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        attn <span class="op">=</span> <span class="va">self</span>.dropout(F.softmax(attn, dim<span class="op">=-</span><span class="dv">1</span>))</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>        output <span class="op">=</span> torch.matmul(attn, v)</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> output, attn</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PositionwiseFeedForward(nn.Module):</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' A two-feed-forward-layer module '''</span></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_in, d_hid, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_1 <span class="op">=</span> nn.Linear(d_in, d_hid) <span class="co"># position-wise</span></span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_2 <span class="op">=</span> nn.Linear(d_hid, d_in) <span class="co"># position-wise</span></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_norm <span class="op">=</span> nn.LayerNorm(d_in, eps<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>        residual <span class="op">=</span> x</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer_norm(x)</span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.w_2(F.relu(<span class="va">self</span>.w_1(x)))</span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout(x)</span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a>        x <span class="op">+=</span> residual</span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MultiHeadAttention(nn.Module):</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' Multi-Head Attention module '''</span></span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_head, d_model, d_k, d_v, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_head <span class="op">=</span> n_head</span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_k <span class="op">=</span> d_k</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.d_v <span class="op">=</span> d_v</span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_qs <span class="op">=</span> nn.Linear(d_model, n_head <span class="op">*</span> d_k, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_ks <span class="op">=</span> nn.Linear(d_model, n_head <span class="op">*</span> d_k, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w_vs <span class="op">=</span> nn.Linear(d_model, n_head <span class="op">*</span> d_v, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc <span class="op">=</span> nn.Linear(n_head <span class="op">*</span> d_v, d_model, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attention <span class="op">=</span> ScaledDotProductAttention(temperature<span class="op">=</span>d_k <span class="op">**</span> <span class="fl">0.5</span>)</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_norm <span class="op">=</span> nn.LayerNorm(d_model, eps<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, q, k, v, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>        d_k, d_v, n_head <span class="op">=</span> <span class="va">self</span>.d_k, <span class="va">self</span>.d_v, <span class="va">self</span>.n_head</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>        sz_b, len_q, len_k, len_v <span class="op">=</span> q.size(<span class="dv">0</span>), q.size(<span class="dv">1</span>), k.size(<span class="dv">1</span>), v.size(<span class="dv">1</span>)</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>        residual <span class="op">=</span> q</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.layer_norm(q)</span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pass through the pre-attention projection: b x lq x (n*dv)</span></span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Separate different heads: b x lq x n x dv</span></span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.w_qs(q).view(sz_b, len_q, n_head, d_k)</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> <span class="va">self</span>.w_ks(k).view(sz_b, len_k, n_head, d_k)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.w_vs(v).view(sz_b, len_v, n_head, d_v)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transpose for attention dot product: b x n x lq x dv</span></span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>        q, k, v <span class="op">=</span> q.transpose(<span class="dv">1</span>, <span class="dv">2</span>), k.transpose(<span class="dv">1</span>, <span class="dv">2</span>), v.transpose(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mask <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>            mask <span class="op">=</span> mask.unsqueeze(<span class="dv">0</span>).unsqueeze(<span class="dv">0</span>)  <span class="co"># For head axis broadcasting.</span></span>
<span id="cb21-104"><a href="#cb21-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-105"><a href="#cb21-105" aria-hidden="true" tabindex="-1"></a>        q, attn <span class="op">=</span> <span class="va">self</span>.attention(q, k, v, mask<span class="op">=</span>mask)</span>
<span id="cb21-106"><a href="#cb21-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-107"><a href="#cb21-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Transpose to move the head dimension back: b x lq x n x dv</span></span>
<span id="cb21-108"><a href="#cb21-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)</span></span>
<span id="cb21-109"><a href="#cb21-109" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> q.transpose(<span class="dv">1</span>, <span class="dv">2</span>).contiguous().view(sz_b, len_q, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb21-110"><a href="#cb21-110" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> <span class="va">self</span>.dropout(<span class="va">self</span>.fc(q))</span>
<span id="cb21-111"><a href="#cb21-111" aria-hidden="true" tabindex="-1"></a>        q <span class="op">+=</span> residual</span>
<span id="cb21-112"><a href="#cb21-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-113"><a href="#cb21-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> q</span>
<span id="cb21-114"><a href="#cb21-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-115"><a href="#cb21-115" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DecoderLayer(nn.Module):</span>
<span id="cb21-116"><a href="#cb21-116" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' Compose with three layers '''</span></span>
<span id="cb21-117"><a href="#cb21-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-118"><a href="#cb21-118" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, d_model, d_inner, n_head, d_k, d_v, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb21-119"><a href="#cb21-119" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(DecoderLayer, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb21-120"><a href="#cb21-120" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.slf_attn <span class="op">=</span> MultiHeadAttention(n_head, d_model, d_k, d_v, dropout<span class="op">=</span>dropout)</span>
<span id="cb21-121"><a href="#cb21-121" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pos_ffn <span class="op">=</span> PositionwiseFeedForward(d_model, d_inner, dropout<span class="op">=</span>dropout)</span>
<span id="cb21-122"><a href="#cb21-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-123"><a href="#cb21-123" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, dec_input, mask<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb21-124"><a href="#cb21-124" aria-hidden="true" tabindex="-1"></a>        dec_output <span class="op">=</span> <span class="va">self</span>.slf_attn(dec_input, dec_input, dec_input, mask<span class="op">=</span>mask)</span>
<span id="cb21-125"><a href="#cb21-125" aria-hidden="true" tabindex="-1"></a>        dec_output <span class="op">=</span> <span class="va">self</span>.pos_ffn(dec_output)</span>
<span id="cb21-126"><a href="#cb21-126" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> dec_output</span>
<span id="cb21-127"><a href="#cb21-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-128"><a href="#cb21-128" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Transformer(nn.Module):</span>
<span id="cb21-129"><a href="#cb21-129" aria-hidden="true" tabindex="-1"></a>    <span class="co">''' A decoder model with self attention mechanism. '''</span></span>
<span id="cb21-130"><a href="#cb21-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-131"><a href="#cb21-131" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, device, mode<span class="op">=</span><span class="st">'none'</span>):</span>
<span id="cb21-132"><a href="#cb21-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-133"><a href="#cb21-133" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb21-134"><a href="#cb21-134" aria-hidden="true" tabindex="-1"></a>        n_layers <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb21-135"><a href="#cb21-135" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_size <span class="op">=</span> <span class="dv">3</span> <span class="cf">if</span> mode <span class="op">==</span> <span class="st">'pixel_location'</span> <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb21-136"><a href="#cb21-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-137"><a href="#cb21-137" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> mode <span class="op">==</span> <span class="st">'pos_encoding'</span>:</span>
<span id="cb21-138"><a href="#cb21-138" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.pos_enc <span class="op">=</span> PositionalEncoding(<span class="dv">1</span>, n_position<span class="op">=</span><span class="dv">784</span>)</span>
<span id="cb21-139"><a href="#cb21-139" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc_in <span class="op">=</span> nn.Linear(<span class="va">self</span>.input_size, <span class="dv">64</span>)</span>
<span id="cb21-140"><a href="#cb21-140" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer_stack <span class="op">=</span> nn.ModuleList([</span>
<span id="cb21-141"><a href="#cb21-141" aria-hidden="true" tabindex="-1"></a>            DecoderLayer(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">64</span>, dropout<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb21-142"><a href="#cb21-142" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layers)])</span>
<span id="cb21-143"><a href="#cb21-143" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc_out <span class="op">=</span> nn.Linear(<span class="dv">64</span>, <span class="dv">1</span>)</span>
<span id="cb21-144"><a href="#cb21-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-145"><a href="#cb21-145" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'mask'</span>, torch.zeros(<span class="dv">784</span>, <span class="dv">784</span>))</span>
<span id="cb21-146"><a href="#cb21-146" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">784</span>):</span>
<span id="cb21-147"><a href="#cb21-147" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.mask[i, :i] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb21-148"><a href="#cb21-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-149"><a href="#cb21-149" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mode <span class="op">=</span> mode</span>
<span id="cb21-150"><a href="#cb21-150" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> device</span>
<span id="cb21-151"><a href="#cb21-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-152"><a href="#cb21-152" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-153"><a href="#cb21-153" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb21-154"><a href="#cb21-154" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">'pixel_location'</span>:</span>
<span id="cb21-155"><a href="#cb21-155" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> append_location(x, <span class="va">self</span>.device)</span>
<span id="cb21-156"><a href="#cb21-156" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>).view(batch_size, <span class="dv">784</span>, <span class="va">self</span>.input_size)</span>
<span id="cb21-157"><a href="#cb21-157" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.mode <span class="op">==</span> <span class="st">'pos_encoding'</span>:</span>
<span id="cb21-158"><a href="#cb21-158" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.view(batch_size, <span class="dv">784</span>, <span class="va">self</span>.input_size)</span>
<span id="cb21-159"><a href="#cb21-159" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.pos_enc(x)</span>
<span id="cb21-160"><a href="#cb21-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb21-161"><a href="#cb21-161" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x.view(batch_size, <span class="dv">784</span>, <span class="va">self</span>.input_size)</span>
<span id="cb21-162"><a href="#cb21-162" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat((torch.zeros(batch_size, <span class="dv">1</span>, <span class="va">self</span>.input_size).to(<span class="va">self</span>.device), x[:, :<span class="op">-</span><span class="dv">1</span>]), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-163"><a href="#cb21-163" aria-hidden="true" tabindex="-1"></a>        <span class="co"># -- Forward</span></span>
<span id="cb21-164"><a href="#cb21-164" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.relu(<span class="va">self</span>.fc_in(x))</span>
<span id="cb21-165"><a href="#cb21-165" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, dec_layer <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.layer_stack):</span>
<span id="cb21-166"><a href="#cb21-166" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> dec_layer(x, mask<span class="op">=</span><span class="va">self</span>.mask)</span>
<span id="cb21-167"><a href="#cb21-167" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc_out(x)</span>
<span id="cb21-168"><a href="#cb21-168" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(batch_size, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb21-169"><a href="#cb21-169" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb21-170"><a href="#cb21-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-171"><a href="#cb21-171" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> nll(<span class="va">self</span>, x):</span>
<span id="cb21-172"><a href="#cb21-172" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.to(<span class="va">self</span>.device)</span>
<span id="cb21-173"><a href="#cb21-173" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>(x)</span>
<span id="cb21-174"><a href="#cb21-174" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> F.binary_cross_entropy_with_logits(logits, x)</span>
<span id="cb21-175"><a href="#cb21-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-176"><a href="#cb21-176" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> sample(<span class="va">self</span>, n):</span>
<span id="cb21-177"><a href="#cb21-177" aria-hidden="true" tabindex="-1"></a>        samples <span class="op">=</span> torch.zeros(n, <span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>).to(<span class="va">self</span>.device)</span>
<span id="cb21-178"><a href="#cb21-178" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb21-179"><a href="#cb21-179" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> r <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb21-180"><a href="#cb21-180" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">28</span>):</span>
<span id="cb21-181"><a href="#cb21-181" aria-hidden="true" tabindex="-1"></a>                    logits <span class="op">=</span> <span class="va">self</span>(samples)[:, :, r, c]</span>
<span id="cb21-182"><a href="#cb21-182" aria-hidden="true" tabindex="-1"></a>                    probs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb21-183"><a href="#cb21-183" aria-hidden="true" tabindex="-1"></a>                    samples[:, :, r, c] <span class="op">=</span> torch.bernoulli(probs)</span>
<span id="cb21-184"><a href="#cb21-184" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> samples.cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T16:28:55.035729Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T16:28:55.017560Z&quot;}" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> {<span class="st">'epochs'</span>: <span class="dv">21</span>, <span class="st">'lr'</span>: <span class="fl">0.0002</span>}</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Transformer(device, mode<span class="op">=</span><span class="st">'pixel_location'</span>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-executetime="{&quot;end_time&quot;:&quot;2020-06-06T16:45:59.260528Z&quot;,&quot;start_time&quot;:&quot;2020-06-06T16:28:58.670359Z&quot;}" data-execution_count="21">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>train_epochs(model, train_loader, test_loader, train_args)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0 Test Loss: 0.2513 bits/dim
Epoch 10 Test Loss: 0.1693 bits/dim
Epoch 20 Test Loss: 0.1486 bits/dim
Test Loss 0.10297279804944992</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-18-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-18-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-18-output-5.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2020-05-20-Autoregressive-Generative-Models_files/figure-html/cell-18-output-6.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="pixelsnail" class="level2">
<h2 class="anchored" data-anchor-id="pixelsnail">PixelSNAIL</h2>
<p>We’ve already covered a lot til now (Yeah! I know…). The last model we will review is PixelSNAIL which adopt masked self-attention approaches inspired by <a href="https://arxiv.org/pdf/1707.03141.pdf">SNAIL</a>.<br>
The key idea behind PixelSNAIL is to introduce attention blocks, in a style similar to Self Attention, into neural autoregressive modelling.<br>
The PixelSNAIL model is composed of two blocks:</p>
<ul>
<li><p>Residual block: This block is as same as gated unit block in PixelCNN that we’ve seen so far.</p></li>
<li><p>Attention block: This block performs a single key-value lookup. It projects the input to a lower dimensionality to produce the keys and values and then uses softmax-attention like in Transformer model.</p></li>
</ul>
<p><img src="my_icons/pixelSNAIL.png" title="Figure 11: PixelSNAIL block. Source[15]" class="img-fluid"></p>
<p>The way how PixelSNAIL integrated self-attention blocks is quite interesting because it allows to model long-range depenencies between pixels in image, equip all conditionals with the ability to refer to all of their available context. Moreover, each conditional can access any pixels in its context through the attention operator, easy information access of remote pixels improves modeling of long-range statistics.</p>
<p><img src="my_icons/pixelSNAIL_arch.png" title="Figure 12: PixelSNAIL architecture. Source[15]" class="img-fluid"></p>
<section id="flexible-ordering" class="level3">
<h3 class="anchored" data-anchor-id="flexible-ordering">Flexible ordering</h3>
<p>We’ve seen in PixelCNN or other architectures, the pixel ordering is raster scanning where along each row left pixels come before right pixels and top rows come before bottom rows. The raster scan order-ing only has a small number neighboring pixels available in the conditioning context <span class="math inline">\(\bf x_1, . . . , x_{i−1}\)</span>: only to the left and above and most of the context is wasted on regions that might have little correlation with the current pixel like the far top-right corner. Since we can access any pixels in its context through attention operator, PixelSNAIL allows zigzag ordering.</p>
<p><img src="my_icons/pixels-ordering.png" title="Figure 13: Pixels ordering. Source[15]" class="img-fluid"></p>
</section>
</section>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<p>[1]. <a href="https://sites.google.com/view/berkeley-cs294-158-sp20/home">Deep Unsupervised Learning course – UC Berkeley</a><br>
[2]. Brian Keng <a href="http://bjlkeng.github.io/posts/autoregressive-autoencoders/">Autoregressive autoencoder</a><br>
[3]. Bengio et al.&nbsp;2014 <a href="https://arxiv.org/pdf/1206.5538.pdf">Representation Learning: A Review and NewPerspectives</a><br>
[4] <a href="https://wiki.math.uwaterloo.ca/statwiki/index.php?title=STAT946F17/Conditional_Image_Generation_with_PixelCNN_Decoders">wiki notes- Conditional Image Generation with PixelCNN Decoders</a><br>
[5]. Van den Oord et al.&nbsp;2016 <a href="https://arxiv.org/pdf/1601.06759.pdf">Pixel Recurrent Neural Networks</a>. ICML 2016.<br>
[6]. Van den Oord et al.&nbsp;2016 <a href="https://arxiv.org/pdf/1606.05328.pdf">Conditional Image Generation with PixelCNN Decoders</a><br>
[7] Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma <a href="https://arxiv.org/pdf/1701.05517.pdf">PixelCNN++ A PixelCNN Implementation with Discretized Logistic Mixture Likelihood and Other Modifications</a><br>
[8] Germain, Mathieu, Karol Gregor, Iain Murray, and Hugo Larochelle. <a href="https://arxiv.org/pdf/1502.03509.pdf">Made: Masked autoencoder for distribution estimation</a> ICML 2015.<br>
[9] https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173<br>
[10] Fisher Yu, Vladlen Koltun <a href="https://arxiv.org/pdf/1511.07122.pdf">Multi-scale context aggregation by dilated convolution</a>. ICLR 2016<br>
[11] Van den Oord et al.&nbsp;2016 <a href="https://arxiv.org/pdf/1609.03499.pdf">WaveNet - A generative model for raw audio</a><br>
[12] Tom Le Paine1, Pooya Khorram, Shiyu Chang, Yang Zhang ,Prajit Ramachandran, Mark A. Hasegawa-Johnson &amp; Thomas S. Huang. 2016 <a href="https://arxiv.org/pdf/1611.09482.pdf">Fast Wavenet generation model</a><br>
[13] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser <a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is All You Need</a><br>
[14] Jay Alammar <a href="https://jalammar.github.io/illustrated-transformer/">Illustrated transformer</a><br>
[15] Xi Chen, Nikhil Mishra, Mostafa Rohaninejad, Pieter Abbee <a href="https://arxiv.org/pdf/1712.09763.pdf">PixelSNAIL: An Improved Autoregressive Generative Model</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>